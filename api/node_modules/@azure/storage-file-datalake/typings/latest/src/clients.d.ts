import { HttpRequestBody, TokenCredential } from "@azure/core-http";
import { AnonymousCredential } from "./credentials/AnonymousCredential";
import { StorageSharedKeyCredential } from "./credentials/StorageSharedKeyCredential";
import { DataLakeLeaseClient } from "./DataLakeLeaseClient";
import { DirectoryCreateOptions, DirectoryCreateResponse, FileAppendOptions, FileAppendResponse, FileCreateOptions, FileCreateResponse, FileFlushOptions, FileFlushResponse, FileReadOptions, FileReadResponse, Metadata, PathAccessControlItem, PathCreateOptions, PathCreateResponse, PathDeleteOptions, PathDeleteResponse, PathGetAccessControlOptions, PathGetAccessControlResponse, PathGetPropertiesOptions, PathGetPropertiesResponse, PathHttpHeaders, PathMoveOptions, PathMoveResponse, PathPermissions, PathResourceType, PathSetAccessControlOptions, PathSetAccessControlResponse, PathSetHttpHeadersOptions, PathSetHttpHeadersResponse, PathSetMetadataOptions, PathSetMetadataResponse, PathSetPermissionsOptions, PathSetPermissionsResponse } from "./models";
import { Pipeline, StoragePipelineOptions } from "./Pipeline";
import { StorageClient } from "./StorageClient";
/**
 * A DataLakePathClient represents a URL to the Azure Storage path (directory or file).
 *
 * @export
 * @class DataLakePathClient
 * @extends {StorageClient}
 */
export declare class DataLakePathClient extends StorageClient {
    /**
     * pathContext provided by protocol layer.
     *
     * @private
     * @type {PathOperations}
     * @memberof DataLakePathClient
     */
    private pathContext;
    /**
     * blobClient provided by @azure/storage-blob package.
     *
     * @private
     * @type {BlobClient}
     * @memberof DataLakePathClient
     */
    private blobClient;
    /**
     * Creates an instance of DataLakePathClient from url and credential.
     *
     * @param {string} url A Client string pointing to Azure Storage data lake path (directory or file), such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/directory" or "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory?sasString".
     * @param {(StorageSharedKeyCredential | AnonymousCredential | TokenCredential)} [credential] Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the @azure/identity package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
     * @param {StoragePipelineOptions} [options] Optional. Options to configure the HTTP pipeline.
     * @memberof DataLakePathClient
     */
    constructor(url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions);
    /**
     * Creates an instance of DataLakePathClient from url and pipeline.
     *
     * @param {string} url A Client string pointing to Azure Storage data lake path (directory or file), such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/directory" or "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory?sasString".
     * @param {Pipeline} pipeline Call newPipeline() to create a default
     *                            pipeline, or provide a customized pipeline.
     * @memberof DataLakePathClient
     */
    constructor(url: string, pipeline: Pipeline);
    /**
     * Name of current file system.
     *
     * @readonly
     * @type {string}
     * @memberof DataLakePathClient
     */
    get fileSystemName(): string;
    /**
     * Name of current path (directory or file).
     *
     * @readonly
     * @type {string}
     * @memberof DataLakePathClient
     */
    get name(): string;
    /**
     * Convert current DataLakePathClient to DataLakeDirectoryClient if current path is a directory.
     *
     * @returns {DataLakeDirectoryClient}
     * @memberof DataLakePathClient
     */
    toDirectoryClient(): DataLakeDirectoryClient;
    /**
     * Convert current DataLakePathClient to DataLakeFileClient if current path is a file.
     *
     * @returns {DataLakeFileClient}
     * @memberof DataLakePathClient
     */
    toFileClient(): DataLakeFileClient;
    /**
     * Get a {@link DataLakeLeaseClient} that manages leases on the path (directory or file).
     *
     * @param {string} [proposeLeaseId] Optional. Initial proposed lease Id.
     * @returns {DataLakeLeaseClient}
     * @memberof DataLakePathClient
     */
    getDataLakeLeaseClient(proposeLeaseId?: string): DataLakeLeaseClient;
    /**
     * Create a directory or path.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param {PathResourceType} resourceType Resource type, "directory" or "file".
     * @param {PathCreateOptions} [options={}] Optional. Options when creating path.
     * @returns {Promise<PathCreateResponse>}
     * @memberof DataLakePathClient
     */
    create(resourceType: PathResourceType, options?: PathCreateOptions): Promise<PathCreateResponse>;
    /**
     * Delete current path (directory or file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
     *
     * @param {boolean} [recursive] Required and valid only when the resource is a directory. If "true", all paths beneath the directory will be deleted.
     * @param {PathDeleteOptions} [options={}] Optional. Options when deleting path.
     * @returns {Promise<PathDeleteResponse>}
     * @memberof DataLakePathClient
     */
    delete(recursive?: boolean, options?: PathDeleteOptions): Promise<PathDeleteResponse>;
    /**
     * Returns the access control data for a path (directory of file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/getproperties
     *
     * @param {PathGetAccessControlOptions} [options={}] Optional. Options when getting file access control.
     * @returns {Promise<PathGetAccessControlResponse>}
     * @memberof DataLakePathClient
     */
    getAccessControl(options?: PathGetAccessControlOptions): Promise<PathGetAccessControlResponse>;
    /**
     * Set the access control data for a path (directory of file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param {PathAccessControlItem[]} acl The POSIX access control list for the file or directory.
     * @param {PathSetAccessControlOptions} [options={}] Optional. Options when setting path access control.
     * @returns {Promise<PathSetAccessControlResponse>}
     * @memberof DataLakePathClient
     */
    setAccessControl(acl: PathAccessControlItem[], options?: PathSetAccessControlOptions): Promise<PathSetAccessControlResponse>;
    /**
     * Sets the file permissions on a path.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param {PathPermissions} permissions The POSIX access permissions for the file owner, the file owning group, and others.
     * @param {PathSetPermissionsOptions} [options={}] Optional. Options when setting path permissions.
     * @returns {Promise<PathSetPermissionsResponse>}
     * @memberof DataLakePathClient
     */
    setPermissions(permissions: PathPermissions, options?: PathSetPermissionsOptions): Promise<PathSetPermissionsResponse>;
    /**
     * Returns all user-defined metadata, standard HTTP properties, and system properties
     * for the path (directory or file).
     *
     * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if
     * they originally contained uppercase characters. This differs from the metadata keys returned by
     * the methods of {@link DataLakeFileSystemClient} that list paths using the `includeMetadata` option, which
     * will retain their original casing.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-properties
     *
     * @param {PathGetPropertiesOptions} [options={}] Optional. Options when getting path properties.
     * @returns {Promise<PathGetPropertiesResponse>}
     * @memberof DataLakePathClient
     */
    getProperties(options?: PathGetPropertiesOptions): Promise<PathGetPropertiesResponse>;
    /**
     * Sets system properties on the path (directory or file).
     *
     * If no value provided, or no value provided for the specified blob HTTP headers,
     * these blob HTTP headers without a value will be cleared.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties
     *
     * @param {PathHttpHeaders} httpHeaders
     * @param {PathSetHttpHeadersOptions} [options={}]
     * @returns {Promise<PathSetHttpHeadersResponse>}
     * @memberof DataLakePathClient
     */
    setHttpHeaders(httpHeaders: PathHttpHeaders, options?: PathSetHttpHeadersOptions): Promise<PathSetHttpHeadersResponse>;
    /**
     * Sets user-defined metadata for the specified path (directory of file) as one or more name-value pairs.
     *
     * If no option provided, or no metadata defined in the parameter, the path
     * metadata will be removed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-metadata
     *
     * @param {Metadata} [metadata] Optional. Replace existing metadata with this value.
     *                              If no value provided the existing metadata will be removed.
     * @param {PathSetMetadataOptions} [options={}] Optional. Options when setting path metadata.
     * @returns {Promise<PathSetMetadataResponse>}
     * @memberof DataLakePathClient
     */
    setMetadata(metadata?: Metadata, options?: PathSetMetadataOptions): Promise<PathSetMetadataResponse>;
    /**
     * Move directory or file within same file system.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param {string} destinationPath Destination directory path like "directory" or file path "directory/file"
     * @param {PathMoveOptions} [options] Optional. Options when moving directory or file.
     * @returns {Promise<PathMoveResponse>}
     * @memberof DataLakePathClient
     */
    move(destinationPath: string, options?: PathMoveOptions): Promise<PathMoveResponse>;
    /**
     * Move directory or file to another file system.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param {string} destinationFileSystem Destination file system like "filesystem".
     * @param {string} destinationPath Destination directory path like "directory" or file path "directory/file"
     * @param {PathMoveOptions} [options] Optional. Options when moving directory or file.
     * @returns {Promise<PathMoveResponse>}
     * @memberof DataLakePathClient
     */
    move(destinationFileSystem: string, destinationPath: string, options?: PathMoveOptions): Promise<PathMoveResponse>;
}
/**
 * A DataLakeDirectoryClient represents a URL to the Azure Storage directory.
 *
 * @export
 * @class DataLakeDirectoryClient
 * @extends {DataLakePathClient}
 */
export declare class DataLakeDirectoryClient extends DataLakePathClient {
    /**
     * Create a directory.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param {PathResourceType} resourceType Resource type, must be "directory" for DataLakeDirectoryClient.
     * @param {PathCreateOptions} [options] Optional. Options when creating directory.
     * @returns {Promise<PathCreateResponse>}
     * @memberof DataLakeDirectoryClient
     */
    create(resourceType: PathResourceType, options?: PathCreateOptions): Promise<PathCreateResponse>;
    /**
     * Create a directory.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param {DirectoryCreateOptions} [options] Optional. Options when creating directory.
     * @returns {Promise<DirectoryCreateResponse>}
     * @memberof DataLakeDirectoryClient
     */
    create(options?: DirectoryCreateOptions): Promise<DirectoryCreateResponse>;
    /**
     * Creates a {@link DataLakeDirectoryClient} object under current directory.
     *
     * @param {string} subdirectoryName Subdirectory name.
     * @returns {DataLakeDirectoryClient}
     * @memberof DataLakeDirectoryClient
     */
    getSubdirectoryClient(subdirectoryName: string): DataLakeDirectoryClient;
    /**
     * Creates a {@link DataLakeFileClient} object under current directory.
     *
     * @param {string} fileName
     * @returns {DataLakeFileClient}
     * @memberof DataLakeDirectoryClient
     */
    getFileClient(fileName: string): DataLakeFileClient;
}
/**
 * A DataLakeFileClient represents a URL to the Azure Storage file.
 *
 * @export
 * @class DataLakeFileClient
 * @extends {DataLakePathClient}
 */
export declare class DataLakeFileClient extends DataLakePathClient {
    /**
     * pathContextInternal provided by protocol layer.
     *
     * @private
     * @type {PathOperations}
     * @memberof DataLakeFileClient
     */
    private pathContextInternal;
    /**
     * blobClientInternal provided by @azure/storage-blob package.
     *
     * @private
     * @type {BlobClient}
     * @memberof DataLakeFileClient
     */
    private blobClientInternal;
    /**
     * Creates an instance of DataLakeFileClient from url and credential.
     *
     * @param {string} url A Client string pointing to Azure Storage data lake file, such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory/file?sasString".
     * @param {(StorageSharedKeyCredential | AnonymousCredential | TokenCredential)} [credential] Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the @azure/identity package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
     * @param {StoragePipelineOptions} [options] Optional. Options to configure the HTTP pipeline.
     * @memberof DataLakeFileClient
     */
    constructor(url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions);
    /**
     * Creates an instance of DataLakeFileClient from url and pipeline.
     *
     * @param {string} url A Client string pointing to Azure Storage data lake file, such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory/file?sasString".
     * @param {Pipeline} pipeline Call newPipeline() to create a default
     *                            pipeline, or provide a customized pipeline.
     * @memberof DataLakeFileClient
     */
    constructor(url: string, pipeline: Pipeline);
    /**
     * Create a file.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param {PathResourceType} resourceType Resource type, must be "file" for DataLakeFileClient.
     * @param {PathCreateOptions} [options] Optional. Options when creating file.
     * @returns {Promise<PathCreateResponse>}
     * @memberof DataLakeFileClient
     */
    create(resourceType: PathResourceType, options?: PathCreateOptions): Promise<PathCreateResponse>;
    /**
     * Create a file.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param {FileCreateOptions} [options] Optional. Options when creating file.
     * @returns {Promise<FileCreateResponse>}
     * @memberof DataLakeFileClient
     */
    create(options?: FileCreateOptions): Promise<FileCreateResponse>;
    /**
     * Downloads a file from the service, including its metadata and properties.
     *
     * * In Node.js, data returns in a Readable stream readableStreamBody
     * * In browsers, data returns in a promise contentAsBlob
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob
     *
     * * Example usage (Node.js):
     *
     * ```js
     * // Download and convert a file to a string
     * const downloadResponse = await fileClient.read();
     * const downloaded = await streamToString(downloadResponse.readableStreamBody);
     * console.log("Downloaded file content:", downloaded);
     *
     * async function streamToString(readableStream) {
     *   return new Promise((resolve, reject) => {
     *     const chunks = [];
     *     readableStream.on("data", (data) => {
     *       chunks.push(data.toString());
     *     });
     *     readableStream.on("end", () => {
     *       resolve(chunks.join(""));
     *     });
     *     readableStream.on("error", reject);
     *   });
     * }
     * ```
     *
     * Example usage (browser):
     *
     * ```js
     * // Download and convert a file to a string
     * const downloadResponse = await fileClient.read();
     * const downloaded = await blobToString(await downloadResponse.contentAsBlob);
     * console.log("Downloaded file content", downloaded);
     *
     * async function blobToString(blob: Blob): Promise<string> {
     *   const fileReader = new FileReader();
     *   return new Promise<string>((resolve, reject) => {
     *     fileReader.onloadend = (ev: any) => {
     *       resolve(ev.target!.result);
     *     };
     *     fileReader.onerror = reject;
     *     fileReader.readAsText(blob);
     *   });
     * }
     * ```
     *
     * @param {number} [offset=0] Optional. Offset to read file, default value is 0.
     * @param {number} [count] Optional. How many bytes to read, default will read from offset to the end.
     * @param {FileReadOptions} [options={}] Optional. Options when reading file.
     * @returns {Promise<FileReadResponse>}
     * @memberof DataLakeFileClient
     */
    read(offset?: number, count?: number, options?: FileReadOptions): Promise<FileReadResponse>;
    /**
     * Uploads data to be appended to a file. Data can only be appended to a file.
     * To apply perviously uploaded data to a file, call flush.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param {HttpRequestBody} body Content to be uploaded.
     * @param {number} offset Append offset in bytes.
     * @param {number} length Length of content to append.
     * @param {FileAppendOptions} [options={}] Optional. Options when appending data.
     * @returns {Promise<FileAppendResponse>}
     * @memberof DataLakeFileClient
     */
    append(body: HttpRequestBody, offset: number, length: number, options?: FileAppendOptions): Promise<FileAppendResponse>;
    /**
     * Flushes (writes) previously appended data to a file.
     *
     * @param {number} position File position to flush.
     *                          This parameter allows the caller to upload data in parallel and control the order in which it is appended to the file.
     *                          It is required when uploading data to be appended to the file and when flushing previously uploaded data to the file.
     *                          The value must be the position where the data is to be appended. Uploaded data is not immediately flushed, or written,
     *                          to the file. To flush, the previously uploaded data must be contiguous, the position parameter must be specified and
     *                          equal to the length of the file after all data has been written, and there must not be a request entity body included
     *                          with the request.
     * @param {FileFlushOptions} [options={}] Optional. Options when flushing data.
     * @returns {Promise<FileFlushResponse>}
     * @memberof DataLakeFileClient
     */
    flush(position: number, options?: FileFlushOptions): Promise<FileFlushResponse>;
}
//# sourceMappingURL=clients.d.ts.map